# ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ï¼šåŸºäºPythonçš„ç†è®ºä¸å®ç°ã€‹

[TOC]

**Link**ï¼šhttp://www.ituring.com.cn/book/1921

<img src="./assets/image-20251018205707810.png" alt="image-20251018205707810" style="zoom:5%;" />

**è¡¨è¿°è§„åˆ™**

<img src="./assets/image-20251019023611235.png" alt="image-20251019023611235" style="zoom: 33%;" />

## ç¬¬1ç«  Pythonå…¥é—¨

### 1.1 Pythonæ˜¯ä»€ä¹ˆ

reading...

### 1.2 Pythonçš„å®‰è£…

è€ƒè™‘createä¸€ä¸ªé€šç”¨çš„å­¦ä¹ ç¯å¢ƒ

ç»¼åˆå¯¹æ¯”studyã€researchã€learnã€testã€mainã€playç­‰åç§°ï¼Œæœ€ç»ˆé€‰ç”¨**lab**ã€‚



ç›®å‰æœ€æ–°Pythonç‰ˆæœ¬ä¸º3.13ï¼Œè€ƒè™‘åˆ°å…¼å®¹æ€§ï¼Œé€‰æ‹©3.12ç‰ˆæœ¬

`conda create --name lab python=3.12`

é‡åˆ°ç½‘ç»œé—®é¢˜ï¼Œè®¾ç½®USTCé•œåƒæºé‡æ–°å®‰è£…

<img src="./assets/image-20251018233403818.png" alt="image-20251018233403818" style="zoom:25%;" />

### 1.3 Pythonè§£é‡Šå™¨

coding...

å…³é—­Pythonè§£é‡Šå™¨ï¼šWindowsï¼šCtrl-Z  + Enter

### 1.4 Pythonè„šæœ¬æ–‡ä»¶

è€ƒè™‘ç›®å½•ç»“æ„ï¼š

- ç« èŠ‚ä¼˜å…ˆï¼š/ch1/code

- **ç±»å‹ä¼˜å…ˆ**ï¼š/code/ch1

### 1.5 Numpy

coding...

å¹¿æ’­æ˜¯é€šè¿‡æ‰©å±•å®ç°å½¢çŠ¶å®ç°çš„

ç†è§£ä»¥ä¸‹ä»£ç 

```python
A = np.array([1, 2], [3, 4])
B = np.array([10, 20])
A * B
```

```python
X[X > 15]
```

### 1.6 Matplotlib

coding...

## ç¬¬2ç«  æ„ŸçŸ¥æœº

### 2.1 æ„ŸçŸ¥æœºæ˜¯ä»€ä¹ˆ

reading...

### 2.2 ç®€å•é€»è¾‘ç”µè·¯

reading...

### 2.3 æ„ŸçŸ¥æœºçš„å®ç°

coding...

`x = np.array(x1, x2)`âŒ

`x = np.array((x1, x2))`âœ”

`x = np.array([x1, x2])`âœ”

### 2.4 æ„ŸçŸ¥æœºçš„å±€é™æ€§

ä¸Šè¿°æ„ŸçŸ¥æœºå¯ç†è§£ä¸ºç”¨ä¸€æ¡ç›´çº¿åˆ†å‰²äºŒç»´å¹³é¢ï¼Œå› æ­¤æ— æ³•å®ç°å¼‚æˆ–é—¨

### 2.5 å¤šå±‚æ„ŸçŸ¥æœº

å•å±‚æ„ŸçŸ¥æœºæ— æ³•åˆ†ç¦»çº¿æ€§ç©ºé—´

```python
def XOR(x1, x2):
    s1 = NAND(x1, x2)
    s2 = OR(x1, x2)
    y = AND(s1, s2)
    return y
```

### 2.6 ä»ä¸éé—¨åˆ°è®¡ç®—æœº

reading...

## ç¬¬3ç«  ç¥ç»ç½‘ç»œ

### 3.1 ä»æ„ŸçŸ¥æœºåˆ°ç¥ç»ç½‘ç»œ

reading...

### 3.2 æ¿€æ´»å‡½æ•°

ä¹¦ä¸­ `np.int` å·²è¢«å¼ƒç”¨

`np.int_` ä¸ºæ›´æ¨èçš„ç”¨æ³•

```python
def step_function(x):
    y = x > 0
    return y.astype(np.int_)
```



ä¹¦ä¸­ `import matplotlib.pylab as plt`

æ¨è `import matplotlib.pyplot as plt`



pythonä¸­ç›´æ¥å†™`plt.show`ï¼ˆæ²¡åŠ ()ï¼‰ä¹Ÿä¸ä¼šæŠ¥é”™ï¼Œè¡¨ç¤ºå‡½æ•°å¼•ç”¨ï¼Œåªæœ‰åŠ ()æ‰è¡¨ç¤ºå‡½æ•°è°ƒç”¨



ä¸ºä»€ä¹ˆpythonä¸­è¿ç®—ç¬¦å¯ä»¥ç›´æ¥å‚ä¸np.arrayè¿ç®—ï¼Œä½†æ˜¯è‡ªå®šä¹‰å‡½æ•°ä¸è¡Œï¼Ÿ

- **è¿ç®—ç¬¦**èƒ½å·¥ä½œæ˜¯å› ä¸ºNumPyé‡è½½äº†å®ƒä»¬
- **è‡ªå®šä¹‰å‡½æ•°**éœ€è¦æ˜¾å¼ä½¿ç”¨NumPyå‡½æ•°æˆ–`np.vectorize`æ¥è·å¾—ç›¸åŒçš„è¡Œä¸º
- æˆ–ç¡®ä¿å‡½æ•°æ”¯æŒæ•°ç»„è¿ç®—
- æœ€ä½³å®è·µæ˜¯åœ¨è‡ªå®šä¹‰å‡½æ•°ä¸­**ä½¿ç”¨NumPyå‡½æ•°**è€Œä¸æ˜¯Pythonå†…ç½®æ“ä½œç¬¦



- `np.max(0, x)`ï¼šé”™è¯¯ç”¨æ³•ï¼Œ`np.max()` ç”¨äºæ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼
- `np.maximum(0, x)`ï¼šæ­£ç¡®ç”¨æ³•ï¼Œé€å…ƒç´ æ¯”è¾ƒä¸¤ä¸ªè¾“å…¥ï¼Œè¿”å›æ¯ä¸ªä½ç½®çš„æœ€å¤§å€¼

### 3.3 å¤šç»´æ•°ç»„çš„è¿ç®—

~~åœ¨NumPyä¸­ï¼Œä¸€ç»´æ•°ç»„å’ŒäºŒç»´æ•°ç»„çš„ä¹˜æ³•è¡Œä¸ºç¡®å®å­˜åœ¨å·®å¼‚ï¼Ÿ~~

- ~~å®é™…ä¸Šï¼Œ`*` è¿ç®—ç¬¦åœ¨NumPyä¸­å¯¹äºä»»ä½•ç»´åº¦çš„æ•°ç»„éƒ½æ˜¯æ‰§è¡Œé€å…ƒç´ ä¹˜æ³•~~
- ~~çœ‹ä¼¼ä¸ä¸€è‡´çš„è¡Œä¸ºï¼Œæ˜¯ç”±äºNumPyçš„å¹¿æ’­æœºåˆ¶~~



ä¸ºä»€ä¹ˆè¿™ä¸ªå¯ä»¥æ­£å¸¸ç®—ï¼ŸXæ˜¯(2,)ï¼ŒWæ˜¯(2, 3)

```python
import numpy as np

X = np.array([1, 2])
print(X.shape)

W = np.array([[1, 3, 5], [2, 4, 6]])
print(W.shape)

Y = np.dot(X, W)
print(Y.shape)
```

`np.dot(a, b)` çš„ç»´åº¦åŒ¹é…è§„åˆ™æ˜¯ï¼š

- **æœ€åä¸€ä¸ªç»´åº¦**çš„ `a` å¿…é¡»ä¸ **ç¬¬ä¸€ä¸ªç»´åº¦** çš„ `b` ç›¸åŒ¹é…

```python
# æƒ…å†µ1ï¼šä¸¤ä¸ªä¸€ç»´æ•°ç»„ â†’ ç‚¹ç§¯ï¼ˆæ ‡é‡ï¼‰
a = np.array([1, 2])
b = np.array([3, 4])
np.dot(a, b)  # 1Ã—3 + 2Ã—4 = 11

# æƒ…å†µ2ï¼šä¸€ç»´ä¸äºŒç»´ â†’ çŸ©é˜µ-å‘é‡ä¹˜æ³•
a = np.array([1, 2])        # (2,)
b = np.array([[1, 3, 5],    # (2, 3)
              [2, 4, 6]])
np.dot(a, b)  # (3,)

# æƒ…å†µ3ï¼šä¸¤ä¸ªäºŒç»´æ•°ç»„ â†’ çŸ©é˜µä¹˜æ³•
a = np.array([[1, 2]])      # (1, 2)
b = np.array([[1, 3, 5],    # (2, 3)
              [2, 4, 6]])
np.dot(a, b)  # (1, 3)
```

### 3.4 3å±‚ç¥ç»ç½‘è·¯çš„å®ç°

coding...

### 3.5 è¾“å‡ºå±‚çš„è®¾è®¡

æ³¨æ„ï¼š

è¯¥å‡½æ•°åœ¨aå­˜åœ¨è¾ƒå¤§å…ƒç´ æ—¶ä¼šå‡ºé”™nan

```python
def softmax(a):
    y = np.exp(a) / np.sum(np.exp(a))
    return y
```

æ”¹ä¸º

```python
def softmax(a):
    c = np.max(a)
    return np.exp(a - c) / np.sum(np.exp(a - c))
```

### 3.6æ‰‹å†™æ•°å­—è¯†åˆ«

PIL = Python Imaging Libraryï¼ˆPython å›¾åƒå¤„ç†åº“ï¼‰

PIL Image çš„ modeï¼ŒMNIST æ˜¯'L'ï¼ˆç°åº¦ï¼‰

> 
>
> ### âœ… æ€»ç»“
>
> - `from PIL import Image` æ˜¯ Python å¤„ç†å›¾åƒçš„**æ ‡å‡†æ–¹å¼**ï¼ˆå®é™…ç”¨çš„æ˜¯ Pillow åº“ï¼‰
> - **`torchvision` å†…éƒ¨ç”¨ PIL åŠ è½½å›¾åƒ**ï¼Œå†æ ¹æ®ä½ çš„ `transform` å†³å®šæ˜¯å¦è½¬æˆ Tensor
> - ä½ ç°åœ¨ç”¨ `transforms.ToTensor()`ï¼Œæ‰€ä»¥**çœ‹ä¸åˆ° PIL Image**ï¼Œä½†å®ƒåœ¨åº•å±‚é»˜é»˜å·¥ä½œ
> - å¦‚æœä½ ä»¥åè¦å¤„ç†è‡ªå·±çš„å›¾ç‰‡æ•°æ®é›†ï¼Œå°±ä¼šç»å¸¸ç”¨åˆ° `Image.open()`
>
> ğŸ’¡ **å°çŸ¥è¯†**ï¼š
> ä½ ä¹‹å‰é‡åˆ°çš„ `RuntimeError: Numpy is not available`ï¼Œå…¶å®æ˜¯å› ä¸º `torchvision` åœ¨æŠŠ PIL Image è½¬ Tensor æ—¶ï¼Œä¸­é—´ä¼šç»è¿‡ NumPyï¼Œæ‰€ä»¥ NumPy å¿…é¡»å­˜åœ¨ï¼



```python
def init_network():
    network = {}

    # ç¬¬1å±‚
    network['W1'] = np.random.randn(784, 50) * 0.01
    network['b1'] = np.zeros(50)

    # ç¬¬2å±‚
    network['W2'] = np.random.randn(50, 100) * 0.01
    network['b2'] = np.zeros(100)

    # ç¬¬ä¸€å±‚
    network['W3'] = np.random.randn(100, 10) * 0.01
    network['b3'] = np.zeros(10)

    return network
```

ä¸ºä»€ä¹ˆç”¨ `np.random.randn`

- æ‰“ç ´å¯¹ç§°æ€§ï¼šå¦‚æœæ‰€æœ‰æƒé‡éƒ½ä¸€æ ·ï¼ˆæ¯”å¦‚å…¨ 0ï¼‰ï¼Œç¥ç»å…ƒä¼šå­¦ä¸åˆ°ä¸åŒç‰¹å¾ã€‚

- é¿å…æ¿€æ´»å‡½æ•°é¥±å’Œï¼šSigmoid åœ¨è¾“å…¥å¾ˆå¤§æˆ–å¾ˆå°æ—¶æ¢¯åº¦æ¥è¿‘ 0ï¼Œå°æƒé‡è®©è¾“å…¥è½åœ¨æ•æ„ŸåŒºåŸŸã€‚

- æ ‡å‡†åšæ³•ï¼šè¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­ç»å…¸çš„ â€œå°éšæœºåˆå§‹åŒ–â€ ç­–ç•¥ã€‚



`np.max` ï¼šæœ€å¤§å€¼

`np.argmax` ï¼šæœ€å¤§å€¼ç´¢å¼•



P78ï¼šbatch_size # æ‰¹æ•°é‡

åº”è¯¥æ˜¯æ‰¹å¤§å°



å¿½ç•¥æ‰€æœ‰åä¸º data çš„ç›®å½•ï¼ˆæ— è®ºåœ¨å“ªä¸€çº§ï¼‰

`data/`

åªå¿½ç•¥æ ¹ç›®å½•ä¸‹çš„ data ç›®å½•ï¼š

`/data`





## ç¬¬4ç«  ç¥ç»ç½‘ç»œçš„å­¦ä¹ 

### 4.1 ä»æ•°æ®ä¸­å­¦ä¹ 

reading...

### 4.2 æŸå¤±å‡½æ•°

coding...

### 4.3 æ•°å€¼å¾®åˆ†

```python
def numerical_diff(f, x):
    h = 1e-4
    return (f(x + h) - f(x - h)) / (2 * h)
```

### 4.4 æ¢¯åº¦

ç”±å…¨éƒ¨å˜é‡çš„åå¯¼æ•°æ±‡æ€»è€Œæˆçš„å‘é‡ç§°ä¸ºæ¢¯åº¦ï¼ˆgradientï¼‰

```python
def numerical_gradient(f, x):
    h = 1e-4
    grad = np.zeros_like(x)  # ç”Ÿæˆå’Œ x å½¢çŠ¶ç›¸åŒçš„æ•°ç»„

    for idx in range(x.size):
        tmp_val = x[idx]

        x[idx] = tmp_val + h
        fxh1 = f(x)

        x[idx] = tmp_val - h
        fxh2 = f(x)

        grad[idx] = (fxh1 - fxh2) / (2 * h)

        x[idx] = tmp_val
    
    return grad
```

è¿™é‡Œä¸èƒ½ä½¿ç”¨æ•´æ•°

<img src="./assets/image-20251028233041589.png" alt="image-20251028233041589"  />

<img src="./assets/image-20251028233124342.png" alt="image-20251028233124342" style="zoom:50%;" />





bugï¼šè¿™ä¿©ä¸ºä»€ä¹ˆä¼šç›¸åŒå•Šï¼Ÿ

<img src="./assets/image-20251028234443903.png" alt="image-20251028234443903" style="zoom:50%;" />

å› ä¸ºæ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¼šæ”¹å˜ `init_x` çš„å€¼

<img src="./assets/image-20251028234517792.png" alt="image-20251028234517792" style="zoom: 50%;" />



è¿™é‡Œæ¢¯åº¦ä¸èƒ½è¿™ä¹ˆå®ç°ï¼Œå¦‚æœxæ˜¯äºŒç»´æ•°ç»„ä¼šæŠ¥é”™

![image-20251101213312148](./assets/image-20251101213312148.png)

![image-20251101220020175](./assets/image-20251101220020175.png)

### 4.5 å­¦ä¹ ç®—æ³•çš„å®ç°

è¿™é‡Œè­¦å‘Šæ˜¯ç”±äºé™æ€æ£€è½¦æ— æ³•æ­£ç¡®è¯†åˆ«x_trainç±»å‹ï¼Œæ¨èæ”¶é›†æ•°æ®æ—¶ä¸è¦ç”¨ç›¸åŒå˜é‡åï¼Œä¾‹å¦‚ `x_train_list`

![image-20251101231949930](./assets/image-20251101231949930.png)

reshapeæœ¬èº«ä¸ä¿®æ”¹å½¢çŠ¶ï¼Œéœ€è¦è¿”å›æ–°çš„å…ƒç´ 

![image-20251101232503676](./assets/image-20251101232503676.png)

å™ªå£°å¤ªå¤§æ²¡æœ‰æ„ä¹‰ï¼Œè€Œä¸”ä¹Ÿå¤ªæ…¢äº†

![image-20251102020401996](./assets/image-20251102020401996.png)

è¿™é‡Œå–ç¬¬ä¸€ä¸ªæ•°æ®è¿›è¡Œæµ‹è¯•

![image-20251102021742946](./assets/image-20251102021742946.png)

![image-20251102022354988](./assets/image-20251102022354988.png)

ä»¥ä¸‹æ˜¯å®Œæ•´çš„è¿­ä»£è¿‡ç¨‹ï¼Œå¯ä»¥çœ‹å‡º

```python
epoch: 0
sofymax: [1.20833628e-07 5.85717628e-03 1.22631110e-06 1.36769664e-05
 9.33650974e-03 6.67757555e-06 2.83617497e-10 1.84447304e-10
 6.59093547e-06 9.84778021e-01]
y: 9
loss: 11.916755577788203
epoch: 1
sofymax: [2.18810743e-07 2.02220274e-02 2.45072080e-06 4.65783482e-05
 2.43778393e-02 6.73709167e-05 1.12091958e-09 5.57739972e-10
 1.25211512e-05 9.55270992e-01]
y: 9
loss: 9.60529713639048
epoch: 2
sofymax: [3.90446550e-07 6.34143433e-02 4.60947797e-06 1.52384357e-04
 5.57100343e-02 5.94327114e-04 4.05464223e-09 1.60742079e-09
 2.30377729e-05 8.80100868e-01]
y: 9
loss: 7.428080692546942
epoch: 3
sofymax: [6.51319350e-07 1.54253693e-01 7.56761995e-06 4.12824604e-04
 9.98098157e-02 4.02023834e-03 1.12893095e-08 3.97889745e-09
 3.89498830e-05 7.41456244e-01]
y: 9
loss: 5.516414088331097
epoch: 4
sofymax: [9.94942190e-07 2.70992340e-01 1.06350644e-05 8.79995511e-04
 1.34454113e-01 2.06341951e-02 2.31071596e-08 8.21316357e-09
 5.85884147e-05 5.72969106e-01]
y: 9
loss: 3.8808056223823644
epoch: 5
sofymax: [1.41535367e-06 3.51612682e-01 1.31626709e-05 1.53904306e-03
 1.42734446e-01 8.53167512e-02 3.71381484e-08 1.47025916e-08
 7.90250497e-05 4.18703423e-01]
y: 9
loss: 2.461384464179898
epoch: 6
sofymax: [1.74823042e-06 3.33394459e-01 1.37250255e-05 2.13465365e-03
 1.21247168e-01 2.63223184e-01 4.71306422e-08 2.16509441e-08
 8.98302059e-05 2.79895164e-01]
y: 1
loss: 1.3347529998336007
epoch: 7
sofymax: [1.69345907e-06 2.37674860e-01 1.14629523e-05 2.19052165e-03
 8.44158207e-02 5.06039690e-01 4.56752505e-08 2.36659928e-08
 8.02342003e-05 1.69585647e-01]
y: 5
loss: 0.6811401731690229
epoch: 8
sofymax: [1.44664537e-06 1.61707692e-01 8.90828130e-06 1.92828493e-03
 5.79457183e-02 6.69853046e-01 3.91510905e-08 2.17418484e-08
 6.49781517e-05 1.08489865e-01]
y: 5
loss: 0.40069692533780593
epoch: 9
sofymax: [1.23248520e-06 1.18349537e-01 7.16601312e-06 1.67506827e-03
 4.28870880e-02 7.59704050e-01 3.35721551e-08 1.93912451e-08
 5.36109410e-05 7.73221935e-02]
y: 5
loss: 0.2748263287780079
```

è¿è¡Œæ—¶é—´å¤ªä¹…äº†ï¼Œå°è¯•æ¨¡å‹ç¼©å°10å€

![image-20251102023224892](./assets/image-20251102023224892.png)

è™½ç„¶æ—¶é—´å¿«äº†ï¼Œä½†æ˜¯æ”¶æ•›é€Ÿåº¦æ…¢äº†å¾ˆå¤šï¼Œæ¨¡å‹å­¦ä¸åŠ¨äº†ï¼Ÿ

![image-20251102023359283](./assets/image-20251102023359283.png)

çœ‹æ¥è¿˜æ˜¯ç»ƒçš„åŠ¨çš„ï¼Œæ¯•ç«Ÿåªæœ‰ä¸€å¼ å›¾ï¼Œä¸å­˜åœ¨æ•°æ®å™ªå£°ï¼Œä¹Ÿå°±ä¸å­˜åœ¨æ¬ æ‹Ÿåˆ

![image-20251102023953764](./assets/image-20251102023953764.png)

çªç„¶æƒ³èµ·æ¥è¿˜æœ‰ä¸ªreluå‡½æ•°æ›´å¿«

![image-20251102024625027](./assets/image-20251102024625027.png)

![image-20251102024614035](./assets/image-20251102024614035.png)

å†è¯•ä¸€ä¸‹ä¸€å¼€å§‹100å±‚çš„æ¨¡å‹

![image-20251102144316057](./assets/image-20251102144316057.png)

å¯ä»¥çœ‹åˆ°æ”¶æ•›é€Ÿåº¦å¿«äº†ä¸æ˜¯ä¸€ç‚¹ï¼Œä¸€ä¸ªephoå°±æ”¶æ•›äº†

![image-20251102150022102](./assets/image-20251102150022102.png)

éœ€è¦å…¼å®¹å¤šç»´æ•°ç»„

ä¸è¿‡è¿™é‡Œ `predict` ç«Ÿç„¶ä¸ç”¨æ”¹ï¼Ÿ

sigmoidå’Œsoftmaxæ˜¯å¦éœ€è¦ä¿®æ”¹ï¼Ÿ

> ### âœ… 1. **Sigmoidï¼šå¤©ç„¶æ”¯æŒå¤šç»´ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰**
>
> - **æ•°å­¦å®šä¹‰**ï¼š
>   *Ïƒ*(*z*)=1+*e*âˆ’*z*1â€‹
>
> - **æ“ä½œæ€§è´¨**ï¼š**é€å…ƒç´ **ï¼ˆelement-wiseï¼‰å‡½æ•°
>
> - **NumPy è¡Œä¸º**ï¼š
>   å¯¹ä»»æ„å½¢çŠ¶çš„æ•°ç»„ï¼ˆ1Dã€2Dã€3D...ï¼‰ï¼Œ`np.exp(-a)` å’Œé™¤æ³•éƒ½ä¼šè‡ªåŠ¨å¹¿æ’­ï¼ˆbroadcastï¼‰ï¼Œ**å¯¹æ¯ä¸ªå…ƒç´ ç‹¬ç«‹è®¡ç®—**ã€‚
>
> - **ç»“è®º**ï¼š
>
>   > âœ… ä½ çš„åŸå§‹ `sigmoid` å‡½æ•° **æ— éœ€ä»»ä½•ä¿®æ”¹**ï¼Œå³å¯æ­£ç¡®å¤„ç†æ‰¹é‡è¾“å…¥ï¼ˆå¦‚ `(N, D)`ï¼‰ã€‚ 
>
> def sigmoid(a):
>
> â€‹    return 1 / (1 + np.exp(-a))  # å¯¹ (N, D) è¾“å…¥ï¼Œè¾“å‡º (N, D)ï¼Œæ¯ä¸ªå…ƒç´ ç‹¬ç«‹è®¡ç®—
>
> ### âœ… 2. **Softmaxï¼šå¿…é¡»æ˜¾å¼æŒ‰â€œè¡Œâ€å½’ä¸€åŒ–ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰**
>
> - **æ•°å­¦å®šä¹‰**ï¼ˆå¯¹å•ä¸ªæ ·æœ¬ï¼‰ï¼š
>   softmax(*z*)*i*â€‹=âˆ‘*j*â€‹*e**z**j*â€‹*e**z**i*â€‹â€‹
> - **å…³é”®ç‚¹**ï¼šåˆ†æ¯æ˜¯**åŒä¸€è¾“å…¥æ ·æœ¬æ‰€æœ‰ç±»åˆ«çš„æŒ‡æ•°å’Œ**ï¼ˆå³å¯¹â€œç±»åˆ«ç»´åº¦â€å½’ä¸€åŒ–ï¼‰
> - **æ‰¹é‡è¾“å…¥æ—¶**ï¼š
>   - è¾“å…¥å½¢çŠ¶ï¼š`(N, C)`ï¼ˆN ä¸ªæ ·æœ¬ï¼ŒC ä¸ªç±»åˆ«ï¼‰
>   - **å¿…é¡»å¯¹æ¯ä¸€è¡Œ**ï¼ˆæ¯ä¸ªæ ·æœ¬ï¼‰ï¼š`axis=1`
> - **ä¸ä¿®æ”¹çš„åæœ**ï¼š
>   - è‹¥ç›´æ¥ç”¨ `np.sum(np.exp(a))`ï¼ˆæ—  `axis` å‚æ•°ï¼‰ï¼š
>     - åˆ†æ¯ = **æ•´ä¸ª batch æ‰€æœ‰å…ƒç´ çš„å’Œ**
>     - ç»“æœï¼šæ¯ä¸ªæ ·æœ¬çš„ softmax è¢«æ•´ä¸ª batch çš„æ•°æ®â€œæ±¡æŸ“â€
>     - **è¾“å‡ºä¸æ˜¯åˆæ³•çš„æ¦‚ç‡åˆ†å¸ƒ**ï¼ˆæ¯è¡Œå’Œ â‰  1ï¼‰

pythonå¹¿æ’­æœºåˆ¶ä»å³å‘å·¦å¯¹é½ï¼Œç›´æ¥å¯¹axisæ±‚å’Œå¯¼è‡´ç¬¬2ç»´æ¶ˆå¤±ï¼Œåˆ™sçš„axis0ç»´ä»å³å‘å·¦ä¸açš„axis=1å¯¹é½ï¼Œä¸æ˜¯softmaxå¸Œæœ›çš„ç»“æœ

ä½¿ç”¨ `keepdims` ä½¿å¾—axis=1ç»´åº¦ä¸ä¼šæ¶ˆå¤±ï¼Œä»è€Œå¹¿æ’­æœºåˆ¶ä¸å‹ç¼©å‰ç›¸åŒ

ä»¥æ­¤ç±»æ¨ï¼Œä½¿ç”¨æ­¤å‚æ•°å¯ä»¥å¯¹ä»»æ„æŸç»´åº¦æ“ä½œï¼Œä¸”åç»­å¹¿æ’­æ—¶æ¢å¤åŸæ¥çš„å½¢çŠ¶

![image-20251102155423730](./assets/image-20251102155423730.png)

æ”¯æŒbatchå¤„ç†åå•æ ·æœ¬åˆè®­ç»ƒä¸äº†äº†

![image-20251102161508292](./assets/image-20251102161508292.png)

ç»ˆäºå•æ ·æœ¬å’Œbatchéƒ½é€šäº†

![image-20251102163045862](./assets/image-20251102163045862.png)

è¯¶ï¼Œä¸ºä»€ä¹ˆæŸå¤±æ˜¯è´Ÿçš„ï¼Ÿ

losså‡½æ•°æ²¡é”™ï¼Œé‚£å°±è¯´æ˜æ˜¯softmaxå‡½æ•°é”™äº†

![image-20251102163213607](./assets/image-20251102163213607.png)

æ”¹æˆæ•°å€¼ç¨³å®šç‰ˆåå¿˜äº†æ”¹a...



ä»¥batch_size = 10è®­ç»ƒï¼Œæ”¶æ•›å¾ˆæ…¢

![image-20251102171438636](./assets/image-20251102171438636.png)



SGD mini-batchå®ç°

![image-20251102180133382](./assets/image-20251102180133382.png)

è®­ç»ƒå¤ªæ…¢äº†ï¼Œè¿™é‡Œå–10æ¬¡ä¸ºä¾‹

![image-20251102180215410](./assets/image-20251102180215410.png)

## ç¬¬5ç«  è¯¯å·®åå‘ä¼ æ’­æ³•

### 5.1 è®¡ç®—å›¾

reading...

### 5.2 é“¾å¼æ³•åˆ™

reading...

è¿™é‡Œä¹¦ç±ä¸­çš„é—®é¢˜æœ‰ç‚¹å¤š

ä½œè€…åƒæ˜¯æ²¡æœ‰å­¦è¿‡å¾®ç§¯åˆ†

å·²åœ¨ä¹¦ç±ä¸­ä¿®æ­£

### 5.3 åå‘ä¼ æ’­

reading...

### 5.4 ç®€å•å±‚çš„å®ç°

è¿™é‡Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼šå…¨è¿æ¥å±‚æ˜¯ç”¨ä¹˜æ³•å±‚å’Œnä¸ªåŠ æ³•å±‚æ‹¼èµ·æ¥çš„å—ï¼Ÿ

è¿™æ ·å¥½åƒä¸å¤ªåˆç†

åŠ æ³•å±‚åªèƒ½æœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œè€Œå…¨è¿æ¥å±‚éœ€è¦å°†nï¼ˆå‘é‡é•¿åº¦ï¼‰ä¸ª w @ x åŠ èµ·æ¥

å¹¶ä¸æ˜¯ï¼Œç”¨çš„æ˜¯ä¸“é—¨çš„Affine

### 5.5 æ¿€æ´»å‡½æ•°å±‚çš„å®ç°

`np.array` `a = b`æ˜¯å¼•ç”¨èµ‹å€¼ï¼Œä¸æ˜¯å¤åˆ¶

### 5.6 Affine/Softmaxå±‚çš„å®ç°

#### Affine

![image-20251109162336441](./assets/image-20251109162336441.png)

#### Softmax



ä¸ºä»€ä¹ˆåç½®é¡¹åå‘ä¼ æ’­æ—¶è¦æ±‚å’Œè€Œä¸æ˜¯æ±‚å‡å€¼ï¼Ÿ

å› ä¸ºæŸå¤±æ˜¯ç´¯è®¡æ±‚å’Œçš„



åå‘ä¼ æ’­æ—¶ä¸ä»…éœ€è¦è®¡ç®—dwï¼Œä¹Ÿéœ€è¦è®¡ç®—dxï¼Œå› ä¸ºå°±æ˜¯é dxç»§ç»­å‘åä¼ æ’­çš„

dwç›´æ¥ä¿å­˜åœ¨æ¢¯åº¦ï¼Œdxç”¨äºreturnç»§ç»­ä¼ æ’­



è®¡ç®—æ¢¯åº¦ä¸»è¦æœ‰ä¸¤ç§

1. `forward` çš„å‚æ•° `x` ï¼Œç”¨äºåå‘ä¼ æ’­ï¼Œç›´æ¥ `return` å³å¯ï¼Œæ— éœ€ä¿å­˜
2. `__init__` çš„å‚æ•° `W` `b`ï¼Œç”¨äºæ›´æ–°å‚æ•°ï¼Œå› æ­¤éœ€è¦ä¿å­˜



æ—¢ç„¶è®­ç»ƒæ—¶å’Œæ¨ç†æ—¶éƒ½ç”¨ä¸åˆ° `loss`ï¼Œä¸ºä»€ä¹ˆè¿˜è¦ `return` å‘¢ï¼Ÿ

```python
class SoftmaxWithLoss:
 def __init__(self):
 self.loss = None # æŸå¤±
 self.y = None # softmaxçš„è¾“å‡º
 self.t = None # ç›‘ç£æ•°æ®ï¼ˆone-hot vectorï¼‰
 def forward(self, x, t):
 self.t = t
 self.y = softmax(x)
 self.loss = cross_entropy_error(self.y, self.t)
 return self.loss
 def backward(self, dout=1):
 batch_size = self.t.shape[0]
 dx = (self.y - self.t) / batch_size
 return dx
```

### 5.7 è¯¯å·®åå‘ä¼ æ’­çš„å®ç°

![image-20251109162705219](./assets/image-20251109162705219.png)

![image-20251109162736808](./assets/image-20251109162736808.png)



ä¹¦é‡Œé”™äº†ï¼Ÿ
P92

<img src="./assets/image-20251109174104507.png" alt="image-20251109174104507" style="zoom:50%;" />

è¿™é‡Œ `t` ä¸èƒ½` reshape` å§ï¼Ÿ

å¯¹äºç¬¬ä¸€ç§æƒ…å†µï¼š`t` å¯ä»¥è‡ªåŠ¨å¹¿æ’­è‡³äº `y` ä¸€æ ·çš„å½¢çŠ¶ï¼Œæ˜¯å¦ `reshpe`å‡å¯

å¯¹äºç¬¬äºŒç« æƒ…å†µï¼š`reshape` æˆ2ç»´å `t` å°±ä¸èƒ½åšç´¢å¼•äº†å•Šï¼Ÿ

æµ‹è¯•ç»“æœå¦‚ä¸‹ï¼š

<img src="./assets/image-20251109174605603.png" alt="image-20251109174605603" style="zoom:33%;" />

è€Œä¸”ç›´æ¥ç”¨ `mean` å³å¯



è¿™é‡Œç¼–è¯‘å™¨ä¸€ç›´warningå¥½çƒ¦å•Š

<img src="./assets/image-20251109183945593.png" alt="image-20251109183945593" style="zoom: 33%;" />

<img src="./assets/image-20251109184040887.png" alt="image-20251109184040887" style="zoom: 33%;" />

- ä¸ºä»€ä¹ˆ `softmax` `return` `loss` è€Œä¸æ˜¯ `y` ï¼Ÿ

> 1. **è§’è‰²å®šä½ï¼šè¿™æ˜¯ä¸€ä¸ªæŸå¤±å±‚ï¼Œä¸æ˜¯æ¿€æ´»å±‚**
>    - å®ƒä½äºç½‘ç»œæœ«ç«¯ï¼Œ**æ²¡æœ‰ä¸‹ä¸€å±‚**ï¼ŒèŒè´£æ˜¯è®¡ç®—**æ ‡é‡æŸå¤±å€¼**ï¼ˆç”¨äºä¼˜åŒ–å’Œç›‘æ§ï¼‰ï¼Œè€Œéè¾“å‡ºæ¦‚ç‡ã€‚
> 2. **è®­ç»ƒæµç¨‹éœ€æ±‚**
>    - è®­ç»ƒæ—¶åªéœ€ `loss` å€¼ï¼ˆç”¨äºæ‰“å°ã€æ—©åœç­‰ï¼‰å’Œä¸­é—´å˜é‡ `y`ã€`t`ï¼ˆç”¨äºåå‘ä¼ æ’­ï¼‰ï¼Œ**æ— éœ€å°† `y` ä¼ å‡º**ã€‚
> 3. **è®¾è®¡ä¸€è‡´æ€§**
>    - ä¸»æµæ¡†æ¶ï¼ˆå¦‚ PyTorch çš„ `CrossEntropyLoss`ï¼‰å‡åªè¿”å› `loss`ï¼Œç¬¦åˆæ ‡å‡†å®è·µã€‚
> 4. **æ¨ç†æ—¶å•ç‹¬ä½¿ç”¨ `softmax(x)`**
>    - è‹¥éœ€é¢„æµ‹æ¦‚ç‡ï¼ˆå¦‚ `predict`ï¼‰ï¼Œåº”**ç›´æ¥è°ƒç”¨ `softmax(x)`**ï¼Œè€Œéé€šè¿‡æŸå¤±å±‚è·å– `y`ã€‚

> âœ… **æ ¸å¿ƒç†å¿µ**ï¼šæŸå¤±å±‚ = è®¡ç®— loss + æä¾›æ¢¯åº¦ï¼›æ¦‚ç‡è¾“å‡º = æ¨ç†é˜¶æ®µå•ç‹¬å¤„ç†ã€‚èŒè´£åˆ†ç¦»ï¼Œæ¥å£æ¸…æ™°ã€‚ 

- ä¸ºä»€ä¹ˆ `predict` `loss` `accuracy` éƒ½æ˜¯ç”¨ `x` ä½œä¸ºå‚æ•°è€Œä¸æ˜¯`y` ï¼Ÿè¿™æ ·ä¸ä¼šé‡å¤è®¡ç®—å—ï¼Ÿ

> 1. **æ¥å£è®¾è®¡åŸåˆ™**  
>    - è¯„ä¼°å‡½æ•°åº”åªä¾èµ–åŸå§‹è¾“å…¥ `x` å’Œæ ‡ç­¾ `t`ï¼Œä¸ä¾èµ–å†…éƒ¨çŠ¶æ€ï¼ˆå¦‚ä¹‹å‰è®¡ç®—çš„ `y`ï¼‰ï¼Œç¡®ä¿**æ— çŠ¶æ€ã€å¯å¤ç°ã€æ˜“è°ƒç”¨**ã€‚
>
> 2. **é¿å…éšå¼ä¾èµ–ä¸é”™è¯¯**  
>    - è‹¥ä¾èµ– `y`ï¼Œéœ€ç¡®ä¿ `forward()` å·²æ­£ç¡®æ‰§è¡Œä¸” `x` æœªå˜ï¼Œææ˜“å¼•å‘**æ—¶åº bug**ã€‚
>
> 3. **â€œé‡ç®—â€ä¼˜äºâ€œç¼“å­˜â€**  
>    - å‰å‘ä¼ æ’­å¼€é”€å°ï¼Œé‡ç®— `y` æ¯”ç»´æŠ¤ç¼“å­˜æ›´**ç®€å•ã€å®‰å…¨ã€é€šç”¨**ã€‚
>    - æ·±åº¦å­¦ä¹ æ¡†æ¶æ™®éé‡‡ç”¨æ­¤ç­–ç•¥ï¼ˆå¦‚ PyTorch/TensorFlowï¼‰ã€‚
>
> 4. **æ”¯æŒä»»æ„æ•°æ®è¯„ä¼°**  
>    - å¯ç›´æ¥å¯¹æ–°æ•°æ®è®¡ç®— loss/accuracyï¼Œæ— éœ€å…ˆè°ƒç”¨ `forward()`ã€‚
>
> > âœ… **æ ¸å¿ƒç†å¿µ**ï¼šå®å¯è½»å¾®é‡å¤è®¡ç®—ï¼Œä¹Ÿè¦ä¿è¯ä»£ç æ¸…æ™°ã€æ— å‰¯ä½œç”¨ã€æ˜“äºç»´æŠ¤ã€‚



çœŸå¿«å•Šåå‘ä¼ æ’­

èƒ½å·®30000å€æ˜¯æ²¡æƒ³åˆ°çš„

![image-20251109223222239](./assets/image-20251109223222239.png)

åˆ†æï¼š

æ•°å€¼æ¢¯åº¦ï¼š

æ€»å‚æ•°é‡çº¦ 784 * 100 = 78400ä¸ª

æ¯ä¸ªå‚æ•°éœ€è¦è®¡ç®—ä¸¤æ¬¡å‰å‘ä¼ æ’­

å…±è®¡çº¦15wæ¬¡

åå‘ä¼ æ’­ï¼š

ä¸å‚æ•°ä¸¤æ— å…³ï¼Œä¸€å…±ä»…éœ€è¦1æ¬¡å‰å‘ä¼ æ’­ + 1æ¬¡åå‘ä¼ æ’­

è¯´æ˜æœ¬ä¾‹ä¸­åå‘ä¼ æ’­çš„æ—¶é—´çº¦ç­‰äºå‰å‘ä¼ æ’­ * 5



![image-20251109231804907](./assets/image-20251109231804907.png)

å¯ä»¥çœ‹åˆ°æ•ˆæœéå¸¸å¥½

è€Œä¸”å¾ˆå¿« 21ç§’å°±è·‘å®Œäº†10000ä¸ªiter

![image-20251109231851782](./assets/image-20251109231851782.png)

å°è¯•æŠŠbatch_sizeæ”¹æˆ100â†’1000ï¼Œiterationæ”¹æˆ10000â†’1000

å¯ä»¥çœ‹åˆ°å¹³å‡æ¯è½®epochçš„æ•ˆæœä¸‹é™äº†

å¹³å‡æ¯æ¬¡æ›´æ–°ï¼ˆè¿™é‡Œç›´æ¥å¯¹æ¯”epoch1å’Œæ›´æ–°åçš„epoch10ï¼‰çš„æ•ˆæœå‡ ä¹æ²¡åŒºåˆ«

æ—¶é—´ä¸ŠåŒºåˆ«ä¸å¤§ 21sâ†’17sï¼Œbatch=1000å¹¶è¡Œæ€§ç¨å¾®å¥½ä¸€ç‚¹ç‚¹ï¼Œè¯´æ˜å·²ç»è¾¾åˆ°cpuæœ€å¤§å¹¶è¡Œæ•ˆç‡ï¼Ÿå¦‚æœæ˜¯GPUå‘¢ï¼Ÿ

ä¹Ÿå°±æ˜¯è¯´æ›´å¤§çš„batchä¸»è¦ä¼˜åŠ¿åœ¨äºå™ªå£°æ›´å°

è¯´æ˜å¯¹äºimageæ•°æ®é›†ï¼Œbatch=100çš„å™ªå£°å·²ç»å¾ˆå°äº†

çªç„¶æƒ³åˆ°ä¸€ä¸ªæ¦‚å¿µï¼š**è¿‡æ‹Ÿåˆ**

å¦‚æœbatchå¤ªå°ï¼Œå¯ä»¥ç†è§£ä¸ºæ¯ä¸€æ¬¡æ›´æ–°æ¢¯åº¦éƒ½åœ¨æœç€æŸä¸ªbatchçš„å±€éƒ¨æœ€ä¼˜æ–¹å‘ä¼˜åŒ–ï¼Œä»è€Œå¯¼è‡´è®­ç»ƒä¸åŠ¨äº†ï¼Œä»è®­ç»ƒç»“æœä¸Šæ¥çœ‹å°±æ˜¯æ¯æ¬¡batchæ›´æ–°çš„gradåå¤æ¨ªè·³ï¼Œæˆ–lossåå¤æ¨ªè·³

è¿™ä¸ªæ—¶å€™æœ‰å¯èƒ½æ¨¡å‹è¿˜æœªå……åˆ†æ‹Ÿåˆè®­ç»ƒé›†ï¼Œåªæ˜¯åœ¨ä¸åœçš„è¿‡æ‹ŸåˆæŸä¸ªbatch

å¯¹äºè¿™ç§æƒ…å†µå¯ä»¥è€ƒè™‘å¢å¤§batchçœ‹çœ‹

æ³¨æ„è¿™é‡Œçš„â€œè¿‡æ‹Ÿåˆâ€ç›¸å¯¹çš„æ˜¯ æŸbatch ç›¸è¾ƒäºtrain_datasetï¼Œ

è€Œé€šå¸¸æ‰€è¯´çš„è¿‡æ‹Ÿåˆæ˜¯æŒ‡ train_dataset ç›¸è¾ƒäºå…¨ä½“åˆ†å¸ƒï¼ˆé€šå¸¸ç”¨test_datasetï¼‰éªŒè¯

batchç›¸è¾ƒäºtrainçš„å…³ç³»å°±æ˜¯trainç›¸è¾ƒäºæ•´ä½“åˆ†å¸ƒçš„å…³ç³»ï¼ˆteståªæ˜¯æ•´ä½“åˆ†å¸ƒçš„ä¸€éƒ¨åˆ†æ ·ä¾‹ï¼‰

ç”±äºè¯¥ç®—æ³•ä½¿ç”¨çš„æ˜¯éšæœºbatchï¼Œä»è€Œå¤©ç„¶çš„é˜²æ­¢äº†æ¨¡å‹å¯¹äºxçš„è¿‡æ‹Ÿåˆï¼ˆå› ä¸ºæ‹Ÿåˆåˆ°ä¸€å®šç¨‹åº¦åå°±ä¼šåœ¨ä¸åŒbatchä¹‹é—´æ‘‡æ‘†ï¼‰

è¿™ä¸ªæ—¶å€™æ˜¯å¢å¤§batchè®©æ¨¡å‹æ›´å¥½çš„æ‹Ÿåˆtrainè¿˜æ˜¯åœæ­¢ï¼Ÿ

æˆ‘è§‰å¾—å¯ä»¥çœ‹ä¸€ä¸‹è¿™ä¸ªæ—¶å€™trainå’Œtestçš„å…³ç³»ï¼Œtestè¿˜åœ¨ä¸Šå‡çš„è¯å¯ä»¥è¯´æ˜trainè¿˜æ²¡æœ‰è¿‡æ‹Ÿåˆï¼Œå¯ä»¥å°è¯•é€šè¿‡å¢å¤§batchæ›´å¥½çš„æ‹Ÿåˆtrain

![image-20251109232514683](./assets/image-20251109232514683.png)

è®¡åˆ’ï¼šå¯¹æ¯”torch



bugï¼šå‡†ç¡®ç‡å§‹ç»ˆæ˜¯ä¸€ä¸ªå€¼

è®¡ç®—æ¢¯åº¦çš„ `dW` å†™å‡º `w` äº†

bugï¼šè®­ç»ƒç‰¹åˆ«æ…¢ï¼ˆç›¸è¾ƒäºæ­£å¸¸ï¼‰

`Affine` å¿˜ + åæ‰§ `b` äº†



è¿™é‡Œé‡æ–°å†™äº†ä¸€éï¼Œå‘ç°è®­ç»ƒçªç„¶æ…¢äº†å¾ˆå¤š

<img src="./assets/image-20251114183530088.png" alt="image-20251114183530088" style="zoom: 50%;" />

ç»ˆäºå‘ç°é—®é¢˜äº†ï¼ŒåŒºåˆ«å°±åœ¨äº

![image-20251114183807602](./assets/image-20251114183807602.png)

ä¸ºä»€ä¹ˆåˆå§‹å‚æ•°å¯¹äºæ”¶æ•›é€Ÿåº¦å½±å“è¿™ä¹ˆå¤§ï¼Ÿè§6.2

## ç¬¬6ç«  ä¸å­¦ä¹ ç›¸å…³çš„æŠ€å·§

### 6.1 å‚æ•°çš„æ›´æ–°

#### SGD

```python
class SGD:
    def __init__(self, lr=0.01) -> None:
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
```

#### Momentum

```python
class Momentum:
    def __init__(self, lr=0.01, momentum=0.9) -> None:
        self.lr = lr
        self.momentum=momentum
        self.v = None

    def update(self, params, grads):
        if self.v == None:
            self.v = {}
            for key, val in params.items():
                self.v =[key] = np.zeros_like(val)
                
        for key in params.key():
            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]
            params[key] += self.v[key]
```

æ¢¯åº¦èµ·åˆ°åŠ é€Ÿåº¦çš„ä½œç”¨

#### AdaGrad

ä¸ºä»€ä¹ˆè¦ç´¯è®¡æ‰€æœ‰å†å²æ¢¯åº¦çš„å’Œï¼Ÿè¿™æ ·ä¸æ˜¯è¶Šå­¦è¶Šæ…¢å—ï¼Ÿ

æˆ‘è®¤ä¸ºå½“å‰çš„å­¦ä¹ ç‡ä¹‹åº”è¯¥å–å†³äºå½“å‰ï¼ˆæˆ–ä¸´è¿‘ï¼‰çš„ä¿¡æ¯ï¼Œè€Œä¸å†å²æ— å…³ã€‚

è€ƒè™‘ä¸€ç§ç­–ç•¥ï¼šåªè®°å½•æœ€è¿‘å‡ æ¬¡çš„æ¢¯åº¦æƒ…å†µï¼Œæ¢¯åº¦è¶Šå¤§å­¦ä¹ ç‡å°±è¶Šå°ï¼Œæˆ–æ˜¯ä¸Momentumç»“åˆï¼Œvè¶Šå¤§å­¦ä¹ ç‡è¶Šå°ã€‚

ä»è¿™ä¸ªè§’åº¦ç†è§£çš„è¯ï¼Œå¯å°†lrè§†ä¸ºæ—¶é—´å°ºåº¦ï¼Œå³éœ€è¦é‡æ–°è°ƒæ•´æ–¹å‘çš„é¢‘ç‡ã€‚

vè´Ÿè´£è°ƒæ•´æ–¹å‘ï¼Œè€Œlrå†³å®šæ¯æ¬¡è°ƒæ•´å®Œèµ°å¤šè¿œï¼Œæˆ–æ¯éš”å¤šä¹…é‡æ–°è°ƒæ•´ä¸€æ¬¡ã€‚

```python
class AdaGrad:
    def __init__(self, lr=0.01) -> None:
        self.lr = lr
        self.h = None

    def update(self, params, grads):
        if self.h == None:
            self.h = {}
            for key, val in params.item():
                self.h[key] = np.zeros_like(val)

        for key in params.key():
            self.h[key] += np.square(grads[key])
            params[key] -= self.lr * grads[key] / np.sqrt(self.h[key] + 1e-7)
```

ä¸ºä»€ä¹ˆè¦å…ˆå¹³æ–¹å†å¼€æ–¹ï¼Ÿ

å¹³æ–¹æ˜¯ä¸ºäº†æ¶ˆé™¤è´Ÿæ•°

å¼€æ–¹æ˜¯ä¸ºäº†é˜²æ­¢æ¢¯åº¦è¡°å‡è¿‡å¿«

#### Adam

ä¹¦ä¸­æœªè¯¦è§£ï¼Œå…·ä½“å¯ç›´æ¥æŸ¥é˜…åŸæ–‡ã€‚

### 6.2 æƒé‡çš„åˆå§‹å€¼

coding...

![image-20251130163326146](./assets/image-20251130163326146.png)

### 6.3 Batch Normalization

ä¸ºä»€ä¹ˆbatch normalä¼šæ˜¯æœ‰æ•ˆçš„ï¼Ÿ

æ˜¯å¦ä½¿ç”¨äº†batch normalå°±æ²¡å¿…è¦åˆå§‹åŒ–æƒé‡ç³»æ•°äº†ï¼Ÿ

ä¸ºä»€ä¹ˆä½¿ç”¨äº†batch normalååè€Œweight_init_std=1å˜æˆæ•ˆæœæœ€å¥½äº†ï¼Ÿï¼ˆå®éªŒç»“æœè§codeï¼‰

![image-20251130163339689](./assets/image-20251130163339689.png)

### 6.4 æ­£åˆ™åŒ–

#### è¿‡æ‹Ÿåˆ

å°† `train_size` ä»60000å‡å°è‡³600ï¼Œå¯è§ `train_acc` å¾ˆå¿«æ”¶æ•›è‡³100%ï¼Œè€Œ `test_acc` æœ€ç»ˆæ”¶æ•›è‡³80%å·¦å³ã€‚ï¼ˆå®éªŒç»“æœè§codeï¼‰

![image-20251130163300061](./assets/image-20251130163300061.png)

é¢å¤–å‘ç°ï¼Œå°† `train_size` å‡å°è‡³600åï¼Œè¿è¡Œæ—¶é—´ä»20så¢åŠ è‡³2minï¼Œç»è¿‡ç ”ç©¶å‘ç°ï¼Œæ˜¯ç”±äºç»¿è‰²éƒ¨åˆ†å ç”¨äº†å¤§éƒ¨åˆ†æ—¶é—´ï¼Œå°†å…¶æ³¨é‡Šæ‰åæå‡è‡³15sã€‚

<img src="./assets/image-20251130162538682.png" alt="image-20251130162538682" style="zoom:50%;" />

#### L1æ­£åˆ™åŒ–

```python
class Affine:
    def __init__(self, W, b, weight_decay=0) -> None:  # å¢åŠ æƒå€¼è¡°å‡ç³»æ•°
        self.W = W
        self.b = b
        self.weight_decay = weight_decay

        self.x = np.array([])

        self.dW = None
        self.db = None

    def forward(self, x):
        self.x = x

        out = np.dot(x, self.W) + self.b

        return out

    def backward(self, dout):
        self.db = np.sum(dout, axis=0)
        self.dW = np.dot(self.x.T, dout) + self.weight_decay * self.W  # å¢åŠ L2loss

        dx = np.dot(dout, self.W.T)

        return dx
```

![image-20251130165313239](./assets/image-20251130165313239.png)

å¯¹æ¯”è¿‡æ‹Ÿåˆçš„å®éªŒç»“æœå‘ç°ï¼Œ `test_acc` å¹¶æ²¡æœ‰å˜å¥½ï¼Œåè€Œ `train_acc` å˜å·®äº†ï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ

æœ¬æ¥ä»¥ä¸ºæ˜¯ `weight_decay` çš„é—®é¢˜ï¼Œç„¶ååšäº†å¯¹ç…§å®ç°

![image-20251130175201304](./assets/image-20251130175201304.png)

å‘ç°è®­ç»ƒæ›´å¹³æ»‘äº†ï¼Œä½†æ˜¯è¿‡æ‹Ÿåˆé—®é¢˜å¹¶æ²¡æœ‰è§£å†³ã€‚

åˆæ­¥åˆ¤æ–­æ˜¯å› ä¸º `train_set` å®åœ¨æ˜¯å¤ªå°äº†ï¼Œæ ¹æœ¬æ— æ³•å­¦ä¹ åˆ° `test_set` çš„çœŸå®åˆ†å¸ƒï¼Œæ‰€ä»¥æ˜¯æ•°æ®åˆ†å¸ƒå™ªå£°çš„é—®é¢˜ï¼Œä¸æ˜¯è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚

å¦‚æœæ˜¯è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œåº”è¯¥ä¼šå‡ºç° `test_acc` é™ä½çš„æƒ…å†µï¼Œä½†æ˜¯å›¾ä¸­ `test_acc` åªæ˜¯æ”¶æ•›ï¼Œå¹¶æ²¡æœ‰ä¸‹é™ã€‚



å½¢å¦‚ `dropdout_ratio` `weight_decay` è¿™æ ·çš„å‚æ•°ï¼Œåº”è¯¥åœ¨ `class Net` ä¸­è®¾ç½®é»˜è®¤å‚æ•°è¿˜æ˜¯åº”è¯¥åœ¨ `class Layer` ä¸­è®¾ç½®é»˜è®¤å‚æ•°ï¼Ÿ

#### Dropout

```python
class Dropout:
    def __init__(self, dropout_ratio=0) -> None:
        self.dropout_ratio = dropout_ratio
        self.mask = None  # è¿™é‡Œæœ‰ç‚¹åƒrelu

    def forward(self, x, train_flag):  # éœ€è¦åŒºåˆ†è®­ç»ƒå’Œé¢„æµ‹ï¼Œåªæœ‰è®­ç»ƒæ—¶éœ€è¦dropout  # éœ€è¦ç»™æ‰€æœ‰å±‚éƒ½åŠ ä¸Š
        if train_flag:
            self.mask = np.random.rand(*x.shape) > self.dropout_ratio  # è®°å¾—è§£åŒ…s.shape
            out = x * self.mask
        else:
            out = x * (1 - self.dropout_ratio)  # æ³¨æ„è¿™é‡Œä¸æ˜¯ç›´æ¥è¿”å›xï¼Œè€Œæ˜¯è¦å–å¹³å‡
        
        return out

    def backward(self, dout):
        dx = dout * self.mask

        return dx
```

çœ‹èµ·æ¥ç»“æœå¹¶ä¸æ˜¯å¾ˆå¥½å•Šï¼Œ ä¸è¿‡ `train_acc` å’Œ `test_acc` ç¡®å®æ›´æ¥è¿‘äº†ï¼ˆä¹¦ä¸­ç»“æœç±»ä¼¼ï¼‰ã€‚

çŒœæµ‹åŸå› ä¸L1æ­£åˆ™åŒ–ç›¸åŒï¼Œå› ä¸ºè¿™ä¸ªä¾‹å­æ ¹æœ¬å°±æ— æ³•ä½“ç°*â€œè¿‡æ‹Ÿåˆâ€*ã€‚

![image-20251130185225456](./assets/image-20251130185225456.png)

> é›†æˆå­¦ä¹ ä¸ Dropoutæœ‰å¯†åˆ‡çš„å…³ç³»ã€‚è¿™æ˜¯å› ä¸ºå¯ä»¥å°† Dropoutç†è§£ä¸ºï¼Œé€šè¿‡åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­éšæœºåˆ é™¤ç¥ç»å…ƒï¼Œä»è€Œæ¯ä¸€æ¬¡éƒ½è®©ä¸åŒçš„æ¨¡å‹è¿›è¡Œå­¦ä¹ ã€‚å¹¶ä¸”ï¼Œæ¨ç†æ—¶ï¼Œé€šè¿‡å¯¹ç¥ç»å…ƒçš„è¾“å‡ºä¹˜ä»¥åˆ é™¤æ¯”ä¾‹ï¼ˆæ¯”å¦‚ï¼Œ0.5ç­‰ï¼‰ï¼Œå¯ä»¥å–å¾—æ¨¡å‹çš„å¹³å‡å€¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯ä»¥ç†è§£æˆã€‚Dropoutå°†é›†æˆå­¦ä¹ çš„æ•ˆæœï¼ˆæ¨¡æ‹Ÿåœ°ï¼‰é€šè¿‡ä¸€ä¸ªç½‘ç»œå®ç°äº†ã€‚

### 6.5 è¶…å‚æ•°çš„éªŒè¯

æ­¥éª¤**0**

è®¾å®šè¶…å‚æ•°çš„èŒƒå›´ã€‚

æ­¥éª¤**1**

ä»è®¾å®šçš„è¶…å‚æ•°èŒƒå›´ä¸­éšæœºé‡‡æ ·ã€‚

æ­¥éª¤**2**

ä½¿ç”¨æ­¥éª¤1ä¸­é‡‡æ ·åˆ°çš„è¶…å‚æ•°çš„å€¼è¿›è¡Œå­¦ä¹ ï¼Œé€šè¿‡éªŒè¯æ•°æ®è¯„ä¼°è¯†åˆ«ç²¾åº¦ï¼ˆä½†æ˜¯è¦å°†epochè®¾ç½®å¾—å¾ˆå°ï¼‰ã€‚

æ­¥éª¤**3**

é‡å¤æ­¥éª¤1å’Œæ­¥éª¤2ï¼ˆ100æ¬¡ç­‰ï¼‰ï¼Œæ ¹æ®å®ƒä»¬çš„è¯†åˆ«ç²¾åº¦çš„ç»“æœï¼Œç¼©å°è¶…å‚æ•°çš„èŒƒå›´ã€‚



éšæœºé€‰æ‹© ï¼ ç½‘æ ¼æœç´¢

### 6.6 å°ç»“

- å‚ æ•° çš„ æ›´ æ–° æ–¹ æ³•ï¼Œé™¤ äº† SGD ä¹‹ å¤–ï¼Œè¿˜ æœ‰ Momentumã€AdaGradã€Adamç­‰æ–¹æ³•ã€‚
- æƒé‡åˆå§‹å€¼çš„èµ‹å€¼æ–¹æ³•å¯¹è¿›è¡Œæ­£ç¡®çš„å­¦ä¹ éå¸¸é‡è¦ã€‚
- ä½œä¸ºæƒé‡åˆå§‹å€¼ï¼ŒXavieråˆå§‹å€¼ã€Heåˆå§‹å€¼ç­‰æ¯”è¾ƒæœ‰æ•ˆã€‚
- é€šè¿‡ä½¿ç”¨Batch Normalizationï¼Œå¯ä»¥åŠ é€Ÿå­¦ä¹ ï¼Œå¹¶ä¸”å¯¹åˆå§‹å€¼å˜å¾—å¥å£®ã€‚
- æŠ‘åˆ¶è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–æŠ€æœ¯æœ‰æƒå€¼è¡°å‡ã€Dropoutç­‰ã€‚
- é€æ¸ç¼©å°â€œå¥½å€¼â€å­˜åœ¨çš„èŒƒå›´æ˜¯æœç´¢è¶…å‚æ•°çš„ä¸€ä¸ªæœ‰æ•ˆæ–¹æ³•ã€‚

## ç¬¬7ç«  å·ç§¯ç¥ç»ç½‘ç»œ

### 7.1 æ•´ä½“ç»“æ„

å·ç§¯å±‚ï¼ˆConvolutionå±‚ï¼‰

æ± åŒ–å±‚ï¼ˆPoolingå±‚ï¼‰

- [ ] ä¸ºä»€ä¹ˆReLUåœ¨å·ç§¯å±‚å’Œæ± åŒ–å±‚ä¸­é—´ï¼Ÿ

### 7.2 å·ç§¯å±‚

- [ ] ä¸ºä»€ä¹ˆåç½®æ˜¯æ ‡é‡ï¼Ÿå…¨è¿æ¥å±‚çš„åæ‰§ä¸æ˜¯å’Œè¾“å‡ºå½¢çŠ¶ç›¸åŒå—ï¼Ÿ

- [ ] æ»¤æ³¢å™¨æ•°é‡ä¸å°±ç­‰ä»·äºå…¨è¿æ¥å±‚çš„ç¥ç»å…ƒæ•°é‡å—ï¼Ÿä¸ºä»€ä¹ˆç¥ç»å…ƒæ•°é‡æ˜¯å†™åœ¨æœ€åä¸€ç»´ï¼Ÿ

### 7.3 æ± åŒ–å±‚

- [ ] æ± åŒ–å±‚çš„ä½œç”¨æ˜¯å¢å¼ºé²æ£’æ€§ï¼Ÿ

### 7.4 å·ç§¯å±‚å’Œæ± åŒ–å±‚çš„å®ç°

`im2col`  â€œimage to collumnâ€  ä»å›¾åƒåˆ°çŸ©é˜µ

```python
def im2col (input_data, filter_h, filter_w, stride=1, pad=0):  # å…ˆå®ç°ä¸€ä¸ªä¸æ”¯æŒstrideå’Œpadçš„ç‰ˆæœ¬
    batch_size, channels, height, width = input_data.shape

    out_h = height - filter_h + 1
    out_w = width - filter_w + 1

    col = np.zeros((batch_size, channels, out_h, out_w, filter_h, filter_w))

    for h in range(out_h):
        for w in range(out_w):
            col[:, :, h, w, :, :] = input_data[:, :, h:h + filter_h, w:w + filter_w]
    
    col = col.reshape(batch_size * channels * out_h * out_w, filter_h * filter_w)

    return col
```

- [ ] è‡ªå·±å®ç°çš„ç‰ˆæœ¬ï¼Œæ¢ä¸€ä¸ªè§†è§’çœ‹ï¼Œå¥½åƒå¯ä»¥ä¼˜åŒ–æˆå·ç§¯æ ¸å¤§å°çš„å¾ªç¯ï¼Ÿ

- [ ] è¾“å‡ºæ•°æ®æ¯”è¾“å…¥æ•°æ®å¤šå‡ ç»´å°±éœ€è¦åŸºå±‚å¾ªç¯ï¼Ÿ

- [ ] æ¯ä¸ªå·ç§¯æ ¸å¤§å°å°±ä»£è¡¨åŸå›¾ä¸­æ¯ä¸ªåƒç´ éœ€è¦å¤åˆ¶çš„æ¬¡æ•°ï¼Ÿ

- [ ] æ‰€ä»¥å¦‚æœå·ç§¯æ ¸å¤§å°æ˜¯3 * 3ï¼Œé‚£åªéœ€è¦ `for i in range(3): for j in range(3)` ï¼Ÿ



ä½¿ç”¨ `im2col` å±•å¼€è¾“å…¥æ•°æ®åï¼Œä¹‹åå°±åªéœ€å°†å·ç§¯å±‚çš„æ»¤æ³¢å™¨ï¼ˆæƒé‡ï¼‰çºµå‘å±•å¼€ä¸º1åˆ—ï¼Œå¹¶è®¡ç®—2ä¸ªçŸ©é˜µçš„ä¹˜ç§¯å³å¯ï¼ˆå¦‚å›¾ï¼‰ã€‚è¿™å’Œå…¨è¿æ¥å±‚çš„Affineå±‚è¿›è¡Œçš„å¤„ç†åŸºæœ¬ç›¸åŒã€‚

<img src="./assets/image-20251202221532369.png" alt="image-20251202221532369" style="zoom:80%;" />

#### å·ç§¯å±‚

```python
class Convolution:  # ç›®å‰åªæ”¯æŒstride padé‡‡ç”¨é»˜è®¤å‚æ•°
    def __init__(self, W, b, stride=1, pad=0) -> None:
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

    def forward(self, x):
        N, C, H, W = x.shape  # N = batch_size
        FN, C, FH, FW = self.W.shape  # FNæ˜¯æ»¤æ³¢å™¨æ•°é‡ï¼Œå¯¹åº”è¾“å‡ºçš„é€šé“æ•°
        # è¿™ä¸¤ä¸ªé€šé“æ•°ç›¸åŒ

        col = im2col(x, FH, FW, stride=1, pad=0)
        col_W = self.W.reshape(FN, C * FH * FW).T  # ç¬¬0ç»´å˜æˆ N * out_h * out_w  # .Tå’Œstrnapose(1, 0)ç­‰ä»·
        out = np.dot(col, col_W) + self.b

        out_h = H - FH + 1  # åªæ”¯æŒstride=1, pad=0
        out_w = W - FW + 1
        out = out.reshape(N, out_h, out_w, FW).transpose(0, 3, 1, 2)  # é€šé“æ•°å¯ç±»æ¯”ä¸ºAffineå±‚ä¸­çš„å‚æ•°ç»´åº¦

        return out
```

#### æ± åŒ–å±‚

```python
class  Pooling:
    def __init__(self, pool_h, pool_w, stride=1, pad=0) -> None:
        self.pool_h = pool_h  # å·ç§¯å±‚ç›´æ¥ä¼ Wï¼Œè€ŒWå°±åŒ…å«äº†FN, C, FH, FWè¿™å‡ ä¸ªå‚æ•°ï¼Œæ± åŒ–å±‚æ²¡æœ‰å‚æ•°ï¼Œåªéœ€è¦ä¼ å½¢çŠ¶h, w
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad

    def forward(self, x):
        N, C, H, W = x.shape

        col = im2col(x, self.pool_h, self.pool_w, stride=1, pad=0)  # è¿™é‡Œé€šé“æ•°è¿˜åœ¨1ç»´ï¼Œéœ€è¦æŠŠé€šé“æ•°æ”¾åˆ°0ç»´
        col = col.reshape(-1, self.pool_h * self.pool_w)

        out = np.max(col, axis=1)
        
        out_h = H - self.pool_h + 1  # åªæ”¯æŒstride=1, pad=0
        out_w = W - self.pool_w + 1
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)

        return out
```

æ± åŒ–å±‚å’Œå·ç§¯å±‚çš„åŒºåˆ«å°±åœ¨äºé€šé“æ•°çš„å¤„ç†æ–¹å¼ä¸åŒã€‚

### 7.5 CNNçš„å®ç°

- [ ] ä¸ºä»€ä¹ˆæ˜¯ `Conv` â†’ `ReLU` â†’ `Pooling` çš„é¡ºåºï¼Ÿ
- [ ] ä¸ºä»€ä¹ˆåªä½¿ç”¨1å±‚å·ç§¯å±‚ï¼Ÿåªæå–ä¸€æ¬¡ç‰¹å¾ï¼Ÿé‚£ä¸æ˜¯åªèƒ½æå–å·ç§¯æ ¸å¤§å°çš„ç‰¹å¾ï¼Ÿé‚£è¿˜æ˜¯åªæœ‰å±€éƒ¨ä¿¡æ¯å‘€ï¼Ÿ

<img src="./assets/image-20251203154833509.png" alt="image-20251203154833509" style="zoom: 80%;" />

```python
class SimpleConvNet:
    def __init__(self,
                 input_dim=(1, 28, 28),
                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},
                 hidden_size=100,
                 output_size=10,
                 weight_init_std=0.01) -> None:
        
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        conv_output_size = input_size - filter_size + 1
        pool_output_size = conv_output_size - 2 + 1 # é»˜è®¤æ± åŒ–å±‚å¤§å°ä¸º2 * 2ï¼Œæ­¥é•¿ä¸º1

        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)
        self.params['b1'] = np.zeros(filter_num)
        self.params['W2'] = weight_init_std * np.random.randn(filter_num * pool_output_size * pool_output_size, hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)

        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], self.params['stride'], self.params['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2)
        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])
        
        self.last_layer = SoftmaxWithLoss()
    
    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)
            return x
        
    def loss(self, x, t):
            y = self.predict(x)
            return self.last_layer.forward(y, t)
        
    def gradient(self, x, t):
        self.loss(x, t)

        dout = 1
        dout = self.last_layer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()

        for layer in layers:
             dout = layer.backward(dout)
        
        grads = {}
        grads['W1'] = self.layers['Conv1'].dW
        grads['b1'] = self.layers['Conv1'].db
        grads['W2'] = self.layers['Affine1'].dW
        grads['b2'] = self.layers['Affine1'].db
        grads['W3'] = self.layers['Affine2'].dW
        grads['b3'] = self.layers['Affine2'].db

        return grads
```

### 7.6 CNNçš„å¯è§†åŒ–



![image-20251203164053418](./assets/image-20251203164053418.png)

å·¦åŠéƒ¨åˆ†ä¸ºç™½è‰²ã€å³åŠéƒ¨åˆ†ä¸ºé»‘è‰²çš„æ»¤æ³¢å™¨çš„æƒ…å†µä¸‹ï¼Œä¼šå¯¹å‚ç›´æ–¹å‘ä¸Šçš„è¾¹ç¼˜æœ‰å“åº”ã€‚

![image-20251203164222457](./assets/image-20251203164222457.png)

CNNçš„å·ç§¯å±‚ä¸­æå–çš„ä¿¡æ¯ã€‚ç¬¬1å±‚çš„ç¥ç»å…ƒå¯¹è¾¹ç¼˜æˆ–æ–‘å—æœ‰å“åº”ï¼Œç¬¬3å±‚å¯¹çº¹ç†æœ‰å“åº”ï¼Œç¬¬5å±‚å¯¹ç‰©ä½“éƒ¨ä»¶æœ‰å“åº”ï¼Œæœ€åçš„å…¨è¿æ¥å±‚å¯¹ç‰©ä½“çš„ç±»åˆ«ï¼ˆç‹—æˆ–è½¦ï¼‰æœ‰å“åº”ã€‚

![image-20251203164253296](./assets/image-20251203164253296.png)

### 7.7 å…·æœ‰ä»£è¡¨æ€§çš„CNN

#### LeNet

#### AlexNet

### 7.8 å°ç»“

- CNNåœ¨æ­¤å‰çš„å…¨è¿æ¥å±‚çš„ç½‘ç»œä¸­æ–°å¢äº†å·ç§¯å±‚å’Œæ± åŒ–å±‚ã€‚
- ä½¿ç”¨im2colå‡½æ•°å¯ä»¥ç®€å•ã€é«˜æ•ˆåœ°å®ç°å·ç§¯å±‚å’Œæ± åŒ–å±‚ã€‚
- é€šè¿‡CNNçš„å¯è§†åŒ–ï¼Œå¯çŸ¥éšç€å±‚æ¬¡å˜æ·±ï¼Œæå–çš„ä¿¡æ¯æ„ˆåŠ é«˜çº§ã€‚
- LeNetå’ŒAlexNetæ˜¯CNNçš„ä»£è¡¨æ€§ç½‘ç»œã€‚
- åœ¨æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸­ï¼Œå¤§æ•°æ®å’ŒGPUåšå‡ºäº†å¾ˆå¤§çš„è´¡çŒ®ã€‚

## ç¬¬8ç«  æ·±åº¦å­¦ä¹ 

### 8.1 åŠ æ·±ç½‘ç»œ

å¯¹äºè¿™ç§æƒ…å†µï¼Œå¹¶ä¸æ˜¯æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ä¸è¶³æˆ–æ˜¯æ¨¡å‹æ— æ³•æ‹Ÿåˆåˆ†å¸ƒã€‚è€Œæ˜¯æ•°æ®é›†æœ¬èº«å­˜åœ¨ç¼ºé™·/å™ªå£°/éšæœºæ€§ã€‚

æƒ³åˆ°ä¸€ä¸ªä¾‹å­ï¼Œç”¨ç¥ç»ç½‘ç»œé¢„æµ‹æŠ›ç¡¬å¸çš„æ•°æ®é›†ï¼Œæ­£ç¡®ç‡æœ€é«˜ä¹Ÿåªæœ‰50%ã€‚è¿™ä¸æ˜¯ç¥ç»ç½‘ç»œçš„æé™ï¼Œè€Œæ˜¯æ•°æ®é›†çš„æé™ã€‚

<img src="./assets/image-20251204234740222.png" alt="image-20251204234740222" style="zoom: 80%;" />

#### åŠ æ·±å±‚çš„å¥½å¤„

- ä¸æ²¡æœ‰åŠ æ·±å±‚çš„ç½‘ç»œç›¸æ¯”ï¼ŒåŠ æ·±äº†å±‚çš„ç½‘ç»œå¯ä»¥ç”¨æ›´å°‘çš„å‚æ•°è¾¾åˆ°åŒç­‰æ°´å¹³ï¼ˆæˆ–è€…æ›´å¼ºï¼‰çš„è¡¨ç°åŠ›ã€‚
- ä¸æ²¡æœ‰åŠ æ·±å±‚çš„ç½‘ç»œç›¸æ¯”ï¼Œé€šè¿‡åŠ æ·±å±‚ï¼Œå¯ä»¥å‡å°‘å­¦ä¹ æ•°æ®ï¼Œä»è€Œé«˜æ•ˆåœ°è¿›è¡Œå­¦ä¹ ã€‚

### 8.2 æ·±åº¦å­¦ä¹ çš„å°å†å²

- [x] ä¸ºä»€ä¹ˆResNetæ•ˆæœä¼šè¿™ä¹ˆå¥½ï¼Ÿæœ¬è´¨ä¸Šä¸å°±æ˜¯xè·¨äº†ä¸€å±‚å—ï¼Ÿé‚£æ•ˆæœå†å¥½ä¹Ÿåªä¸è¿‡æ˜¯ç›¸å½“äºå±‚æ•°å‡åŠçš„æ•ˆæœç½¢äº†ï¼Ÿ

  ResNetå¹¶éå•å±‚è·³è·ƒï¼Œè€Œæ˜¯å¤šä¸ªæ®‹å·®å—ç©¿æ¢ï¼Œå½¢æˆä»è¾“å…¥åˆ°è¾“å‡ºçš„ç«¯åˆ°ç«¯ç›´é€šè·¯å¾„ï¼è¡°å‡ç›´æ¥ä»æŒ‡æ•°çº§å˜æˆå¸¸æ•°çº§ \[O(1)\] ï¼Œå¹¶éåªæ˜¯æ¬¡æ•°å‡åŠã€‚

### 8.3 æ·±åº¦å­¦ä¹ çš„é«˜é€ŸåŒ–

- [ ] åˆ†å¸ƒå¼å­¦ä¹ ï¼Ÿè”é‚¦å­¦ä¹ ï¼Ÿ

### 8.4 æ·±åº¦å­¦ä¹ çš„åº”ç”¨æ¡ˆä¾‹

#### ç‰©ä½“æ£€æµ‹

- [ ] å¯ä»¥ç«¯åˆ°ç«¯å—ï¼Ÿæ—¢è¾“å…¥æ˜¯å›¾åƒï¼Œè¾“å‡ºæ˜¯ä¸¤ä¸ªåæ ‡ï¼Ÿæˆ–è¾“å‡ºæ˜¯ä¸­å¿ƒ+é•¿å®½ï¼Ÿ

#### å›¾åƒåˆ†å‰²

å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚å¯ä»¥ç›¸äº’æ›¿æ¢å®ç°ç›¸åŒçš„å¤„ç†ã€‚ï¼ˆå·ç§¯æ ¸å’Œå›¾åƒä¸€æ ·å¤§ï¼‰

- [ ] è¿™ä¹ˆè¯´å·ç§¯æ ¸çš„å…¨è¿æ¥å±‚çš„æœ¬è´¨åŒºåˆ«åœ¨äºå°†1ç»´å˜æˆäº†2ç»´ï¼Ÿ

#### å›¾åƒæ ‡é¢˜çš„ç”Ÿæˆ

### 8.5 æ·±åº¦å­¦ä¹ çš„æœªæ¥

#### å›¾åƒé£æ ¼å˜æ¢

#### å›¾åƒçš„ç”Ÿæˆ

- [ ] GANçš„æ€æƒ³æ˜¯å¦é€‚ç”¨äºå…¶ä»–åœºæ™¯ï¼Ÿ

#### è‡ªåŠ¨é©¾é©¶

#### Deep Q-Networkï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰

### 8.6 å°ç»“

- å¯¹äºå¤§å¤šæ•°çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥æœŸå¾…é€šè¿‡åŠ æ·±ç½‘ç»œæ¥æé«˜æ€§èƒ½ã€‚

- åœ¨æœ€è¿‘çš„å›¾åƒè¯†åˆ«å¤§èµ›ILSVRCä¸­ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ç‹¬å é³Œå¤´ï¼Œä½¿ç”¨çš„ç½‘ç»œä¹Ÿåœ¨æ·±åŒ–ã€‚

- VGGã€GoogLeNetã€ResNetç­‰æ˜¯å‡ ä¸ªè‘—åçš„ç½‘ç»œã€‚

- åŸºäºGPUã€åˆ†å¸ƒå¼å­¦ä¹ ã€ä½æ•°ç²¾åº¦çš„ç¼©å‡ï¼Œå¯ä»¥å®ç°æ·±åº¦å­¦ä¹ çš„é«˜é€ŸåŒ–ã€‚

- æ·±åº¦å­¦ä¹ ï¼ˆç¥ç»ç½‘ç»œï¼‰ä¸ä»…å¯ä»¥ç”¨äºç‰©ä½“è¯†åˆ«ï¼Œè¿˜å¯ä»¥ç”¨äºç‰©ä½“æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€‚

- æ·±åº¦å­¦ä¹ çš„åº”ç”¨åŒ…æ‹¬å›¾åƒæ ‡é¢˜çš„ç”Ÿæˆã€å›¾åƒçš„ç”Ÿæˆã€å¼ºåŒ–å­¦ä¹ ç­‰ã€‚æœ€è¿‘ï¼Œæ·±åº¦å­¦ä¹ åœ¨è‡ªåŠ¨é©¾é©¶ä¸Šçš„åº”ç”¨ä¹Ÿå¤‡å—æœŸå¾…ã€‚
